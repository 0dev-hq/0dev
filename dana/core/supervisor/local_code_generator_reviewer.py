import logging
from pydantic import BaseModel
from core.agent_context import AgentContext
from core.code_generation.base_code_generator import GeneratedCodeFormat

logger = logging.getLogger(__name__)


class LocalCodeReviewFormat(BaseModel):
    is_valid: bool
    feedback: str
    suggested_fix: str


class LocalCodeGeneratorReviewer:
    """
    A reviewer that verifies the correctness, quality, and security of the generated code.
    It ensures the code adheres to best practices and aligns with the provided context.
    """

    def __init__(self, llm_client, max_revisions=2):
        """
        Initialize the reviewer with dependencies.

        :param llm_client: An OpenAI client for reviewing code.
        :param max_revisions: Maximum number of times a code revision can be suggested.
        """
        self.llm_client = llm_client
        self.max_revisions = max_revisions

    def review_generated_code(
        self,
        generated_code: GeneratedCodeFormat,
        user_input: str,
        context: AgentContext,
    ) -> LocalCodeReviewFormat:
        """
        Review the generated code to ensure correctness.

        :param generated_code: The code generated by the LocalCodeGenerator.
        :param user_input: The original user request.
        :param context: The contextual state of the agent.
        :return: A dictionary containing the review result.
        """
        logger.info(f"The context for code review: {context}")
        review_prompt = self._generate_review_prompt(
            generated_code=generated_code, user_input=user_input, context=context
        )
        review_result = self.llm_client.answer(
            prompt=review_prompt, formatter=LocalCodeReviewFormat
        )

        logger.info(f"Code review result: {review_result}")

        return {
            "is_valid": review_result.is_valid,
            "feedback": review_result.feedback,
            "suggested_fix": (
                review_result.suggested_fix if not review_result.is_valid else ""
            ),
        }

    def _generate_review_prompt(
        self,
        generated_code: GeneratedCodeFormat,
        user_input: str,
        context: AgentContext,
    ) -> str:
        """
        Generate a prompt for the LLM to review the generated code.

        :param generated_code: The code to be reviewed.
        :param user_input: The original user request.
        :param context: The contextual state of the agent.
        :return: A formatted prompt string for review.
        """

        secrets = {
            secret["name"]: secret["description"]
            for secret in context.get("secrets", [])
        }

        integrations = {
            integration["name"]: {
                "credentials": integration["credentials"],
            }
            for integration in context["integrations"]
        }

        SYSTEM_PROMPT = """You are a highly skilled code reviewer responsible for verifying the correctness, security, and quality of Python code.
        Your task is to review the provided Python code and determine if it meets the requirements outlined in the user's request.
        If the code is incorrect, suggest a revision.
        """

        REVIEW_GUIDELINES = """
        - Verify that the code fulfills the intended task as described in the user request.
        - Confirm that all required dependencies are included and correctly listed.
        - Ensure the `main` function is the correct entry point and all inputs are passed as function arguments.
        - Verify that no placeholder values, hardcoded secrets, or sensitive data are included in the code.
        - Make sure the generated code aligns with the given agent policies and constraints.
        Also verify that the code adheres to the following requirements - none of these requirements should be violated:
        - The code MUST have a function named 'main' that takes all the required inputs as arguments.
        - The `main` function MUST be the entry point of the code, but you can have additional functions if needed.
        - All the code MUST be contained within a single file.
        - If any secret is used in the code, the 'main' function should take an argument named 'secrets' which is a dictionary containing
        all the secrets required by the code.
        - If any of the information needed in the code is provided as a secret, the 'secrets' argument should be used to pass the secret values.
        - The main function should wrap the entire code in a final try-except block to catch any exceptions and return a JSON response in either case
          (success or failure).
        - The code should not have use dummy values or placeholders unless explicitly mentioned in the user inputs.
        """

        CONTEXT = f"""Context:
        Facts: {context.get('facts', 'No facts available')}
        Allowed Intents: {context.get('intents', 'No intents available')}
        Policies: {context.get('policies', 'No policies available')}
        Secrets shared with the agent: {secrets if secrets else 'No secrets available'}
        Integrations shared with the agent: {integrations if integrations else 'No integrations available'}
        User Input: {user_input}
        """

        RESPONSE_FORMAT = """
        Provide a JSON response with:
        - 'is_valid': Whether the generated code is valid.
        - 'feedback': An explanation of the issues found (if any).
        - 'suggested_fix': A suggested modification to improve or correct the code if necessary.
        """

        prompt = [
            {
                "role": "system",
                "content": f"{SYSTEM_PROMPT}\n{REVIEW_GUIDELINES}\n{CONTEXT}\n{RESPONSE_FORMAT}",
            },
            {
                "role": "user",
                "content": f"Review the following Python code:\n\n{generated_code.code}\n\nDoes it meet all requirements?",
            },
        ]

        return prompt
